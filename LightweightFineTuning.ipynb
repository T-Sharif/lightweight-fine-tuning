{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19754b",
   "metadata": {},
   "source": [
    "PEFT technique: I used LoRA (Low-Rank) configuration. I evaluated the BERT model initially and then fine-tuned it on a subset of the BBC News (SetFit/bbc-news) dataset from Hugging Face. The fine-tuning process adapts the model more closely to the task.\n",
    "\n",
    "Model: The base model I used is \"bert-base-uncased\". This model is utilized for both the initial evaluation and the PEFT process (training and evaluation.\n",
    "\n",
    "Evaluation approach: The evaluation is performed using the Trainer class from the Hugging Face's Transformers library. The evaluation strategy is set to \"epoch,\" meaning an evaluation is oerformed after each training epoch. The evaluation metric is accuracy.\n",
    "\n",
    "Fine-tuning dataset: The fine-tuning dataset is the BBC News (SetFit/bbc-news) dataset from Hugging Face. To expedite the process, I used a subset of 1000 samples from the dataset. The dataset is pre-proceesed using the \"bert-base-uncased\" tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "Load a pre-trained Hugging Face model and evaluate its performance prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07db8fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/student/.local/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\n",
      "Requirement already satisfied: multiprocess in /home/student/.local/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/student/.local/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "\u001b[33m  WARNING: The script tabulate is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"datasets==2.15.0\"\n",
    "!pip install datasets transformers\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dea6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f9698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03341828ca494e54aeee3cd90c12130b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/880 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be637b850cc84d43ae603b3618899585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42762bcac2d84288b522f62d3082d53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.87M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66161ef8940a4c779b013b1e92c503aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d7af28fea04c488fb4bb41fb6423e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfb9c53813a4ce7b17092ab7860eab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750305e7206c409686296daf716bc33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0c46c87ba146399a13876631d9a9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be8d4b611b34f2b9884f0f403bd53e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aee585a5a754bdca410b069888340f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752f3e37290a4231ad68e79c1b9bc503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7878ae7d4194141b9fa6697f31345e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bb5ca55ca74586a708d3ac82fae175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7392873a5bd74160b5d9dae3c701ab15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = load_dataset(\"SetFit/bbc-news\")\n",
    "\n",
    "# access the train and test splits - splits where already available from the dataset\n",
    "train_split = dataset[\"train\"]\n",
    "test_split = dataset[\"test\"]\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Had to use a subset beacause the full dataset is too large to train and evaluate on Workspace\n",
    "# Number of samples you want to use from the dataset\n",
    "num_samples = 1000\n",
    "\n",
    "# Create a smaller subset of the train and test datasets\n",
    "small_train_split = train_split.select(range(num_samples))\n",
    "small_test_split = test_split.select(range(num_samples))\n",
    "\n",
    "# Tokenize the smaller datasets\n",
    "small_tokenized_train = small_train_split.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "small_tokenized_test = small_test_split.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "# Define id2label and label2id\n",
    "id2label = {0: \"tech\", 1: \"business\", 2: \"sport\", 3: \"entertainment\", 4: \"politics\"}\n",
    "label2id = {\"tech\": 0, \"business\": 1, \"sport\": 2, \"entertainment\": 3, \"politics\": 4}\n",
    "\n",
    "# load model for sequence classification and define label mapping based on categories\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5,\n",
    "       id2label = id2label,\n",
    "       label2id = label2id)\n",
    "\n",
    "# compute metrics based on the actual labels and the model predictions\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# define training arguments for evaluation\n",
    "training_args = TrainingArguments(\n",
    "output_dir = \"./bbc_news_results\",\n",
    "per_device_eval_batch_size = 10,\n",
    "evaluation_strategy = \"epoch\",\n",
    "save_strategy=\"epoch\",\n",
    "load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b5c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer for pre fine-tuning evaluation\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=small_tokenized_train,\n",
    "eval_dataset=small_tokenized_test,\n",
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fb2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate before fine-tuning\n",
    "pre_eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc56c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Fine-Tuning Evaluation Results:\n",
      " \n",
      " eval_loss               |  1.61727\n",
      " eval_accuracy           |  0.202\n",
      " eval_runtime            | 30.4394\n",
      " eval_samples_per_second | 32.852\n",
      " eval_steps_per_second   |  3.285\n"
     ]
    }
   ],
   "source": [
    "# create a table for a more readable result\n",
    "# referenced a website to create the table\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html\n",
    "df_results = pd.DataFrame.from_dict(pre_eval_results, orient=\"index\")\n",
    "\n",
    "# referenced a webiste to display results for a nice table format\n",
    "#https://pypi.org/project/tabulate/\n",
    "formatted_df = tabulate(df_results, tablefmt=\"presto\")\n",
    "\n",
    "print(f\"Pre-Fine-Tuning Evaluation Results:\\n \\n{formatted_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec9ec89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry on star patsy rowlands dies actress patsy rowlands  known to millions ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banker loses sexism claim a former executive at the london offices of merril...</td>\n",
       "      <td>politics</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liverpool pledge to keep gerrard liverpool chief executive rick parry insist...</td>\n",
       "      <td>tech</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>junk e-mails on relentless rise spam traffic is up by 40%  putting the total...</td>\n",
       "      <td>politics</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new consoles promise big problems making games for future consoles will requ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>celebrities get their skates on former england footballer paul gascoigne wil...</td>\n",
       "      <td>politics</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>net fingerprints combat attacks eighty large net service firms have switched...</td>\n",
       "      <td>tech</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "0  carry on star patsy rowlands dies actress patsy rowlands  known to millions ...   \n",
       "1  banker loses sexism claim a former executive at the london offices of merril...   \n",
       "2  liverpool pledge to keep gerrard liverpool chief executive rick parry insist...   \n",
       "3  junk e-mails on relentless rise spam traffic is up by 40%  putting the total...   \n",
       "4  new consoles promise big problems making games for future consoles will requ...   \n",
       "5  celebrities get their skates on former england footballer paul gascoigne wil...   \n",
       "6  net fingerprints combat attacks eighty large net service firms have switched...   \n",
       "\n",
       "  predictions    true labels  \n",
       "0    politics  entertainment  \n",
       "1    politics       business  \n",
       "2        tech          sport  \n",
       "3    politics           tech  \n",
       "4       sport           tech  \n",
       "5    politics  entertainment  \n",
       "6        tech           tech  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset for visual review with the text, predictions, and labels\n",
    "visual_review = small_tokenized_test.select([0, 5, 34, 85, 107, 268, 436])\n",
    "results = trainer.predict(visual_review)\n",
    "\n",
    "# find a resource for this whole thing\n",
    "mapped_label = {0: \"tech\", 1: \"business\", 2: \"sport\", 3: \"entertainment\", 4: \"politics\"}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": [item[\"text\"] for item in visual_review],\n",
    "    \"predictions\": [mapped_label[p] for p in results.predictions.argmax(axis=1)],\n",
    "    \"true labels\": [mapped_label[l] for l in results.label_ids],\n",
    "})\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "Create a PEFT model from the loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e6bc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7501d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialize LoraConfig and loaded model\n",
    "# Referenced a website to get the LoRA Configuration\n",
    "# https://www.kaggle.com/code/anthonynam/lora-fine-tuning-with-distilbert-7-prompts-v4\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5,\n",
    "        id2label = id2label,\n",
    "        label2id = label2id)\n",
    "\n",
    "# create PEFT model\n",
    "lora_model = get_peft_model(model, config)\n",
    "\n",
    "# unfreeze model parameters\n",
    "for param in lora_model.base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# define arguments for training and evaluation\n",
    "# used this website for information on logging_dir and logging_strategy\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "output_dir = \"./peft_results\",\n",
    "logging_dir = \"./peft_logs\",\n",
    "learning_rate = 2e-5,\n",
    "per_device_train_batch_size = 10,\n",
    "per_device_eval_batch_size = 10,\n",
    "evaluation_strategy = \"epoch\",\n",
    "save_strategy = \"epoch\",\n",
    "logging_strategy = \"epoch\",\n",
    "num_train_epochs = 5,\n",
    "weight_decay=0.01,\n",
    "load_best_model_at_end = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0507495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer for the Peft model with smaller datasets\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_tokenized_train.rename_column('label', 'labels'),\n",
    "    eval_dataset=small_tokenized_test.rename_column('label', 'labels'),\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2776f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 11:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659400</td>\n",
       "      <td>0.131226</td>\n",
       "      <td>0.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.093342</td>\n",
       "      <td>0.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.092960</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.092868</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.15141256654262542, metrics={'train_runtime': 668.3057, 'train_samples_per_second': 7.482, 'train_steps_per_second': 0.748, 'total_flos': 1315925134737000.0, 'train_loss': 0.15141256654262542, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "lora_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e754ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the PEFT model weights\n",
    "lora_model.save_pretrained(\"bert-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "Load the saved PEFT model weights and evaluate the performance of the trained PEFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66e9ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd6b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the saved PEFT model\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"bert-lora\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c131b88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the PEFT model\n",
    "post_eval_results = lora_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83374d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Fine-Tuning Evaluation Results:\n",
      "eval_loss                 0.0928683\n",
      "eval_accuracy             0.98\n",
      "eval_runtime             33.5749\n",
      "eval_samples_per_second  29.784\n",
      "eval_steps_per_second     2.978\n",
      "epoch                     5\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame.from_dict(post_eval_results, orient=\"index\")\n",
    "\n",
    "formatted_df = tabulate(df_results, tablefmt=\"plain\")\n",
    "\n",
    "print(f\"Post-Fine-Tuning Evaluation Results:\\n{formatted_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b387cc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry on star patsy rowlands dies actress patsy rowlands  known to millions ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banker loses sexism claim a former executive at the london offices of merril...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liverpool pledge to keep gerrard liverpool chief executive rick parry insist...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>junk e-mails on relentless rise spam traffic is up by 40%  putting the total...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new consoles promise big problems making games for future consoles will requ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>celebrities get their skates on former england footballer paul gascoigne wil...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>net fingerprints combat attacks eighty large net service firms have switched...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "0  carry on star patsy rowlands dies actress patsy rowlands  known to millions ...   \n",
       "1  banker loses sexism claim a former executive at the london offices of merril...   \n",
       "2  liverpool pledge to keep gerrard liverpool chief executive rick parry insist...   \n",
       "3  junk e-mails on relentless rise spam traffic is up by 40%  putting the total...   \n",
       "4  new consoles promise big problems making games for future consoles will requ...   \n",
       "5  celebrities get their skates on former england footballer paul gascoigne wil...   \n",
       "6  net fingerprints combat attacks eighty large net service firms have switched...   \n",
       "\n",
       "   predictions  label  \n",
       "0            3      3  \n",
       "1            1      1  \n",
       "2            2      2  \n",
       "3            0      0  \n",
       "4            0      0  \n",
       "5            3      3  \n",
       "6            0      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset for visual review with the text, predictions, and labels\n",
    "visual_review = small_tokenized_test.select([0, 5, 34, 85, 107, 268, 436])\n",
    "results = lora_trainer.predict(visual_review)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": [item[\"text\"] for item in visual_review],\n",
    "    \"predictions\": results.predictions.argmax(axis=1),\n",
    "    \"label\": results.label_ids,\n",
    "})\n",
    "\n",
    "# show all the cells\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9200243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Pre-Fine-Tuning and Post-Fine-Tuning Evaluation Results:\n",
      "\n",
      "Metrics                   Accuracy\n",
      "Pre-fine-tuning results   0.202\n",
      "Post-fine-tuning results  0.98\n"
     ]
    }
   ],
   "source": [
    "# create dataframe for accuracy comparison\n",
    "comparison_dict = {\n",
    "    \"Metrics\": [\"Accuracy\"],\n",
    "    \"Pre-fine-tuning results\": [pre_eval_results[\"eval_accuracy\"]],\n",
    "    \"Post-fine-tuning results\": [post_eval_results[\"eval_accuracy\"]],\n",
    "}\n",
    "\n",
    "#create a table for a more readable result\n",
    "df_results = pd.DataFrame.from_dict(comparison_dict, orient=\"index\")\n",
    "\n",
    "formatted_df = tabulate(df_results, tablefmt=\"plain\")\n",
    "\n",
    "print(f\"Comparison of Pre-Fine-Tuning and Post-Fine-Tuning Evaluation Results:\\n\\n{formatted_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f64f7a",
   "metadata": {},
   "source": [
    "The PEFT model had a much higher accuracy than the model before fine-tuning. The model drastically improved from having an 20.2% accuracy before fine-tuning to having a 98% accuracy after fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
